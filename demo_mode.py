#!/usr/bin/env python3
"""
å¤šå±¤æ¬¡LLMé‚è¼¯é¡Œé©—è­‰ç³»çµ± - æ¼”ç¤ºæ¨¡å¼
ä¸éœ€è¦çœŸå¯¦APIï¼Œç”¨æ¨¡æ“¬æ•¸æ“šå±•ç¤ºç³»çµ±å·¥ä½œæµç¨‹
"""

import asyncio
import json
import time
import random
from colorama import init, Fore, Style
from typing import Dict, Any, List

# åˆå§‹åŒ–colorama
init()

class DemoLLMClient:
    """æ¼”ç¤ºæ¨¡å¼çš„æ¨¡æ“¬LLMå®¢æˆ¶ç«¯"""
    
    def __init__(self):
        self.demo_responses = {
            "logic_question": {
                "openai/gpt-4o": {
                    "reasoning": "æ ¹æ“šé‚è¼¯æ¨ç†ï¼Œå°æ˜èªª'å¦‚æœä¸‹é›¨å°±ä¸å»å…¬åœ’'ï¼Œä½†ä»–ä»Šå¤©å»äº†å…¬åœ’ï¼Œæ‰€ä»¥ä»Šå¤©æ²’æœ‰ä¸‹é›¨ã€‚é€™æ˜¯ä¸€å€‹å¦å®šå¾Œä»¶(modus tollens)çš„é‚è¼¯æ¨ç†ã€‚",
                    "answer": "ä»Šå¤©æ²’æœ‰ä¸‹é›¨"
                },
                "openai/gpt-4o-mini": {
                    "reasoning": "ä½¿ç”¨åå‘æ¨ç†ï¼šå¦‚æœä»Šå¤©ä¸‹é›¨â†’å°æ˜ä¸å»å…¬åœ’ã€‚ä½†å°æ˜å»äº†å…¬åœ’ï¼Œæ‰€ä»¥ä»Šå¤©æ²’ä¸‹é›¨ã€‚",
                    "answer": "æ²’æœ‰ä¸‹é›¨"
                },
                "anthropic/claude-3-5-sonnet": {
                    "reasoning": "é€™æ˜¯ç¶“å…¸çš„é‚è¼¯ä¸‰æ®µè«–ã€‚å‰æï¼šä¸‹é›¨â†’ä¸å»å…¬åœ’ï¼›äº‹å¯¦ï¼šå»äº†å…¬åœ’ï¼›çµè«–ï¼šæ²’ä¸‹é›¨ã€‚",
                    "answer": "ä»Šå¤©æ²’æœ‰ä¸‹é›¨"
                }
            },
            "verification": {
                "correct": {
                    "verdict": "Correct",
                    "error_reason": "ç­”æ¡ˆæ­£ç¢ºï¼Œé‚è¼¯æ¨ç†åš´è¬¹ï¼Œç¬¦åˆå¦å®šå¾Œä»¶çš„æ¨ç†è¦å‰‡"
                },
                "incorrect": {
                    "verdict": "Incorrect", 
                    "error_reason": "æ¨ç†éç¨‹æœ‰èª¤ï¼Œæœªæ­£ç¢ºæ‡‰ç”¨é‚è¼¯è¦å‰‡"
                }
            },
            "correction": {
                "original_error_acknowledgment": "æˆ‘ç†è§£äº†åŸå…ˆçš„é‚è¼¯æ¨ç†éŒ¯èª¤",
                "revised_reasoning": "é‡æ–°åˆ†æï¼šé€™æ˜¯å¦å®šå¾Œä»¶çš„é‚è¼¯æ¨ç†ï¼Œå¦‚æœä¸‹é›¨å‰‡ä¸å»å…¬åœ’ï¼Œå»äº†å…¬åœ’èªªæ˜æ²’ä¸‹é›¨",
                "revised_answer": "ä»Šå¤©æ²’æœ‰ä¸‹é›¨"
            },
            "decision": {
                "final_answer": "ä»Šå¤©æ²’æœ‰ä¸‹é›¨",
                "reasoning": "ç¶œåˆåˆ†æä¸‰å€‹æ¨¡å‹çš„å›ç­”ï¼Œéƒ½æŒ‡å‘åŒä¸€çµè«–ã€‚é€™æ˜¯æ¨™æº–çš„å¦å®šå¾Œä»¶é‚è¼¯æ¨ç†ï¼Œçµè«–å¯é ã€‚",
                "evidence_analysis": "æ‰€æœ‰æ¨¡å‹éƒ½æ­£ç¢ºè­˜åˆ¥äº†é€™æ˜¯å¦å®šå¾Œä»¶æ¨ç†ï¼Œç­”æ¡ˆä¸€è‡´æ€§é«˜ï¼Œé‚è¼¯åš´è¬¹ã€‚"
            }
        }
    
    async def call_model(self, model_key: str, prompt: str) -> Dict[str, Any]:
        """æ¨¡æ“¬APIèª¿ç”¨"""
        # æ¨¡æ“¬APIå»¶é²
        await asyncio.sleep(random.uniform(1, 3))
        
        # æ¨¡æ“¬ä¸åŒçš„å›æ‡‰
        if "é‚è¼¯" in prompt or "ä¸‹é›¨" in prompt or "å…¬åœ’" in prompt:
            if model_key in self.demo_responses["logic_question"]:
                response_data = self.demo_responses["logic_question"][model_key]
                response_text = json.dumps(response_data, ensure_ascii=False)
            else:
                response_text = json.dumps({
                    "reasoning": f"[{model_key}æ¨¡æ“¬å›æ‡‰] é€™æ˜¯ä¸€å€‹é‚è¼¯æ¨ç†å•é¡Œ...",
                    "answer": "ä»Šå¤©æ²’æœ‰ä¸‹é›¨"
                }, ensure_ascii=False)
        else:
            response_text = json.dumps({
                "reasoning": f"[{model_key}æ¨¡æ“¬å›æ‡‰] æ ¹æ“šåˆ†æ...",
                "answer": "ç¤ºä¾‹ç­”æ¡ˆ"
            }, ensure_ascii=False)
        
        return {
            'success': True,
            'response': response_text,
            'model': model_key,
            'provider': model_key.split('/')[0],
            'usage': {'input_tokens': 100, 'output_tokens': 50}
        }

class DemoAnsweringLayer:
    """æ¼”ç¤ºç‰ˆå›ç­”å±¤"""
    
    def __init__(self):
        self.demo_client = DemoLLMClient()
    
    async def process_question(self, question: str, models: List[str] = None) -> List[Dict[str, Any]]:
        if models is None:
            models = ['openai/gpt-4o', 'openai/gpt-4o-mini']
        
        print(f"{Fore.CYAN}ğŸ“ å›ç­”å±¤è™•ç†ä¸­...{Style.RESET_ALL}")
        
        results = []
        for model in models:
            print(f"  æ­£åœ¨è™•ç†æ¨¡å‹: {model}")
            
            response = await self.demo_client.call_model(model, question)
            if response['success']:
                parsed = json.loads(response['response'])
                results.append({
                    'model': model,
                    'success': True,
                    'answer': parsed['answer'],
                    'reasoning': parsed['reasoning'],
                    'raw_response': response['response']
                })
            
            await asyncio.sleep(0.5)
        
        return results

class DemoVerificationLayer:
    """æ¼”ç¤ºç‰ˆé©—è­‰å±¤"""
    
    def __init__(self):
        self.demo_client = DemoLLMClient()
    
    async def verify_answers(self, question: str, answers: List[Dict[str, Any]], 
                           verification_models: List[str] = None) -> List[Dict[str, Any]]:
        if verification_models is None:
            verification_models = ['openai/gpt-4o', 'openai/gpt-4o-mini']
        
        print(f"{Fore.CYAN}ğŸ” é©—è­‰å±¤è™•ç†ä¸­...{Style.RESET_ALL}")
        
        verification_results = []
        for answer in answers:
            if answer['success']:
                for verification_model in verification_models:
                    # äº¤å‰é©—è­‰ï¼šä¸è®“æ¨¡å‹é©—è­‰è‡ªå·±
                    if verification_model != answer['model']:
                        print(f"  æ­£åœ¨ä½¿ç”¨ {verification_model} é©—è­‰ {answer['model']} çš„ç­”æ¡ˆ")
                        
                        # æ¨¡æ“¬é©—è­‰çµæœ
                        await asyncio.sleep(1)
                        verification_data = self.demo_client.demo_responses["verification"]["correct"]
                        
                        verification_results.append({
                            'verification_model': verification_model,
                            'target_model': answer['model'],
                            'success': True,
                            'verdict': verification_data['verdict'],
                            'error_reason': verification_data['error_reason']
                        })
        
        return verification_results

class DemoCorrectionLayer:
    """æ¼”ç¤ºç‰ˆè¨‚æ­£å±¤"""
    
    def __init__(self):
        self.demo_client = DemoLLMClient()
    
    async def correct_answers(self, question: str, original_answers: List[Dict[str, Any]], 
                            verification_results: List[Dict[str, Any]], 
                            correction_model: str = None) -> List[Dict[str, Any]]:
        
        print(f"{Fore.CYAN}ğŸ”§ è¨‚æ­£å±¤è™•ç†ä¸­...{Style.RESET_ALL}")
        
        correction_results = []
        
        for answer in original_answers:
            if answer['success']:
                # æª¢æŸ¥æ˜¯å¦éœ€è¦è¨‚æ­£
                needs_correction = False
                for verification in verification_results:
                    if (verification['target_model'] == answer['model'] and 
                        verification.get('verdict') == 'Incorrect'):
                        needs_correction = True
                        break
                
                if needs_correction:
                    print(f"  æ­£åœ¨è¨‚æ­£ {answer['model']} çš„ç­”æ¡ˆ")
                    await asyncio.sleep(1)
                    
                    correction_data = self.demo_client.demo_responses["correction"]
                    correction_results.append({
                        'model': answer['model'],
                        'needs_correction': True,
                        'success': True,
                        'original_answer': answer['answer'],
                        'revised_answer': correction_data['revised_answer'],
                        'original_reasoning': answer['reasoning'],
                        'revised_reasoning': correction_data['revised_reasoning'],
                        'original_error_acknowledgment': correction_data['original_error_acknowledgment'],
                        'correction_applied': True
                    })
                else:
                    correction_results.append({
                        'model': answer['model'],
                        'needs_correction': False,
                        'original_answer': answer['answer'],
                        'revised_answer': answer['answer'],
                        'original_reasoning': answer['reasoning'],
                        'revised_reasoning': answer['reasoning'],
                        'correction_applied': False
                    })
        
        return correction_results

class DemoDecisionLayer:
    """æ¼”ç¤ºç‰ˆæ±ºç­–å±¤"""
    
    def __init__(self):
        self.demo_client = DemoLLMClient()
    
    async def make_final_decision(self, question: str, 
                                original_answers: List[Dict[str, Any]],
                                verification_results: List[Dict[str, Any]],
                                correction_results: List[Dict[str, Any]],
                                decision_model: str = None) -> Dict[str, Any]:
        
        print(f"{Fore.CYAN}âš–ï¸ æ±ºç­–å±¤è™•ç†ä¸­...{Style.RESET_ALL}")
        await asyncio.sleep(2)
        
        decision_data = self.demo_client.demo_responses["decision"]
        
        # è¨ˆç®—ä¿¡å¿ƒåº¦å’Œå…±è­˜åº¦
        correct_count = sum(1 for v in verification_results if v.get('verdict') == 'Correct')
        total_verifications = len(verification_results)
        confidence = correct_count / total_verifications if total_verifications > 0 else 1.0
        
        return {
            'success': True,
            'decision_model': decision_model or 'openai/gpt-4o',
            'final_answer': decision_data['final_answer'],
            'reasoning': decision_data['reasoning'],
            'evidence_analysis': decision_data['evidence_analysis'],
            'answer_confidence': confidence,
            'verification_consensus': {
                'consensus_rate': confidence,
                'agreement_level': 'High Consensus' if confidence >= 0.8 else 'Moderate Consensus',
                'verdict_distribution': {'Correct': correct_count, 'Incorrect': total_verifications - correct_count}
            }
        }

class DemoSystemCoordinator:
    """æ¼”ç¤ºç‰ˆç³»çµ±å”èª¿å™¨"""
    
    def __init__(self):
        self.answering_layer = DemoAnsweringLayer()
        self.verification_layer = DemoVerificationLayer()
        self.correction_layer = DemoCorrectionLayer()
        self.decision_layer = DemoDecisionLayer()
    
    async def process_question(self, question: str, verbose: bool = True) -> Dict[str, Any]:
        """è™•ç†å•é¡Œçš„å®Œæ•´æµç¨‹"""
        
        if verbose:
            print(f"\n{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
            print(f"{Fore.MAGENTA}ğŸš€ é–‹å§‹è™•ç†å•é¡Œ{Style.RESET_ALL}")
            print(f"{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
            print(f"{Fore.BLUE}ğŸ“‹ å•é¡Œï¼š{question}{Style.RESET_ALL}\n")
        
        try:
            # ç¬¬ä¸€å±¤ï¼šå›ç­”å±¤
            if verbose:
                print(f"{Fore.YELLOW}ğŸ”„ ç¬¬ä¸€å±¤ï¼šå¤šæ¨¡å‹å›ç­”{Style.RESET_ALL}")
            answering_results = await self.answering_layer.process_question(question)
            
            # ç¬¬äºŒå±¤ï¼šé©—è­‰å±¤
            if verbose:
                print(f"\n{Fore.YELLOW}ğŸ”„ ç¬¬äºŒå±¤ï¼šäº¤å‰é©—è­‰{Style.RESET_ALL}")
            verification_results = await self.verification_layer.verify_answers(question, answering_results)
            
            # ç¬¬ä¸‰å±¤ï¼šè¨‚æ­£å±¤
            if verbose:
                print(f"\n{Fore.YELLOW}ğŸ”„ ç¬¬ä¸‰å±¤ï¼šéŒ¯èª¤è¨‚æ­£{Style.RESET_ALL}")
            correction_results = await self.correction_layer.correct_answers(question, answering_results, verification_results)
            
            # ç¬¬å››å±¤ï¼šæ±ºç­–å±¤
            if verbose:
                print(f"\n{Fore.YELLOW}ğŸ”„ ç¬¬å››å±¤ï¼šæœ€çµ‚æ±ºç­–{Style.RESET_ALL}")
            decision_result = await self.decision_layer.make_final_decision(question, answering_results, verification_results, correction_results)
            
            # æ•´ç†çµæœ
            result = {
                'layer_results': {
                    'answering': answering_results,
                    'verification': verification_results,
                    'correction': correction_results,
                    'decision': decision_result
                },
                'summary': {
                    'overall_success': decision_result['success'],
                    'total_models_used': len(answering_results),
                    'verification_count': len(verification_results),
                    'corrections_applied': sum(1 for c in correction_results if c.get('correction_applied', False))
                }
            }
            
            if verbose:
                self.print_results(result)
            
            return result
        
        except Exception as e:
            if verbose:
                print(f"{Fore.RED}âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}{Style.RESET_ALL}")
            
            return {
                'layer_results': {'decision': {'success': False, 'error': str(e)}},
                'summary': {'overall_success': False}
            }
    
    def print_results(self, result: Dict[str, Any]):
        """æ‰“å°çµæœ"""
        print(f"\n{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}ğŸ“Š è™•ç†çµæœ{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
        
        decision = result['layer_results']['decision']
        if decision['success']:
            print(f"{Fore.GREEN}âœ… è™•ç†æˆåŠŸ{Style.RESET_ALL}")
            print(f"{Fore.BLUE}ğŸ“‹ æœ€çµ‚ç­”æ¡ˆ: {decision['final_answer']}{Style.RESET_ALL}")
            print(f"{Fore.BLUE}ğŸ“Š ä¿¡å¿ƒç¨‹åº¦: {decision['answer_confidence']:.2%}{Style.RESET_ALL}")
            print(f"{Fore.BLUE}ğŸ¤ é©—è­‰å…±è­˜åº¦: {decision['verification_consensus']['consensus_rate']:.2%}{Style.RESET_ALL}")
            print(f"{Fore.BLUE}ğŸ“ˆ å…±è­˜ç¨‹åº¦: {decision['verification_consensus']['agreement_level']}{Style.RESET_ALL}")
            
            print(f"\n{Fore.CYAN}ğŸ§  æ±ºç­–æ¨ç†:{Style.RESET_ALL}")
            print(f"{decision['reasoning']}")
            
            print(f"\n{Fore.CYAN}ğŸ“‹ è­‰æ“šåˆ†æ:{Style.RESET_ALL}")
            print(f"{decision['evidence_analysis']}")
        else:
            print(f"{Fore.RED}âŒ è™•ç†å¤±æ•—: {decision.get('error', 'æœªçŸ¥éŒ¯èª¤')}{Style.RESET_ALL}")

async def run_demo():
    """é‹è¡Œæ¼”ç¤º"""
    print(f"{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
    print(f"{Fore.MAGENTA}ğŸ­ å¤šå±¤æ¬¡LLMé‚è¼¯é©—è­‰ç³»çµ± - æ¼”ç¤ºæ¨¡å¼{Style.RESET_ALL}")
    print(f"{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
    
    print(f"\n{Fore.CYAN}ğŸ“‹ æ¼”ç¤ºèªªæ˜:{Style.RESET_ALL}")
    print(f"â€¢ é€™æ˜¯æ¨¡æ“¬æ¨¡å¼ï¼Œä¸éœ€è¦çœŸå¯¦APIå¯†é‘°")
    print(f"â€¢ å±•ç¤ºå®Œæ•´çš„å››å±¤è™•ç†æµç¨‹")
    print(f"â€¢ ä½¿ç”¨é è¨­çš„ç¤ºä¾‹å›æ‡‰")
    print(f"â€¢ å¹«åŠ©æ‚¨ç†è§£ç³»çµ±å·¥ä½œåŸç†")
    
    demo_questions = [
        'å°æ˜èªªï¼š"å¦‚æœä»Šå¤©ä¸‹é›¨ï¼Œæˆ‘å°±ä¸å»å…¬åœ’ã€‚"ä»Šå¤©å°æ˜å»äº†å…¬åœ’ã€‚è«‹å•ä»Šå¤©æ˜¯å¦ä¸‹é›¨ï¼Ÿ',
        'æ‰€æœ‰é³¥éƒ½æœƒé£›ã€‚ä¼éµæ˜¯é³¥ã€‚ä¼éµæœƒé£›å—ï¼Ÿ',
        'å¦‚æœAå¤§æ–¼Bï¼ŒBå¤§æ–¼Cï¼Œé‚£éº¼Aå’ŒCçš„é—œä¿‚æ˜¯ä»€éº¼ï¼Ÿ'
    ]
    
    system = DemoSystemCoordinator()
    
    for i, question in enumerate(demo_questions, 1):
        print(f"\n{Fore.YELLOW}{'='*60}{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}ğŸ§ª æ¼”ç¤º {i}: é‚è¼¯æ¨ç†æ¸¬è©¦{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}{'='*60}{Style.RESET_ALL}")
        
        result = await system.process_question(question, verbose=True)
        
        if i < len(demo_questions):
            print(f"\n{Fore.BLUE}æŒ‰Enteréµç¹¼çºŒä¸‹ä¸€å€‹æ¼”ç¤º...{Style.RESET_ALL}")
            input()

def print_api_guide():
    """æ‰“å°APIç”³è«‹æŒ‡å—"""
    print(f"\n{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
    print(f"{Fore.MAGENTA}ğŸ”‘ APIå¯†é‘°ç”³è«‹æŒ‡å—{Style.RESET_ALL}")
    print(f"{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
    
    guides = [
        {
            'name': 'OpenAI (æ¨è–¦)',
            'url': 'https://platform.openai.com/api-keys',
            'features': 'ç©©å®šå¯é ï¼Œè³ªé‡é«˜ï¼Œé©åˆå¤§è¦æ¨¡å¯¦é©—',
            'cost': 'gpt-4o-mini: $0.15/1M tokens (ä¾¿å®œ)',
            'steps': [
                '1. è¨»å†ŠOpenAIå¸³è™Ÿ',
                '2. å‰å¾€APIå¯†é‘°é é¢',
                '3. å‰µå»ºæ–°çš„APIå¯†é‘°',
                '4. è¤‡è£½å¯†é‘°åˆ°.envæ–‡ä»¶'
            ]
        },
        {
            'name': 'Google Gemini (å…è²»é¡åº¦å¤§)',
            'url': 'https://ai.google.dev/',
            'features': 'å…è²»é¡åº¦è¼ƒå¤§ï¼Œé€Ÿåº¦å¿«',
            'cost': 'å…è²»é¡åº¦ + ä»˜è²»é¸é …',
            'steps': [
                '1. ä½¿ç”¨Googleå¸³è™Ÿç™»å…¥',
                '2. å‰å¾€Google AI Studio',
                '3. ç²å–APIå¯†é‘°',
                '4. é…ç½®åˆ°ç’°å¢ƒè®Šé‡'
            ]
        },
        {
            'name': 'Anthropic Claude',
            'url': 'https://console.anthropic.com/',
            'features': 'é‚è¼¯æ¨ç†èƒ½åŠ›å¼·ï¼Œå®‰å…¨æ€§é«˜',
            'cost': '$3/1M input tokens',
            'steps': [
                '1. è¨»å†ŠAnthropicå¸³è™Ÿ',
                '2. å‰å¾€æ§åˆ¶å°',
                '3. ç²å–APIå¯†é‘°',
                '4. é…ç½®ç’°å¢ƒè®Šé‡'
            ]
        }
    ]
    
    for guide in guides:
        print(f"\n{Fore.CYAN}ğŸ”¹ {guide['name']}{Style.RESET_ALL}")
        print(f"   ç¶²å€: {guide['url']}")
        print(f"   ç‰¹é»: {guide['features']}")
        print(f"   è²»ç”¨: {guide['cost']}")
        print(f"   æ­¥é©Ÿ:")
        for step in guide['steps']:
            print(f"     {step}")

if __name__ == "__main__":
    print(f"{Fore.BLUE}é¸æ“‡æ¨¡å¼:{Style.RESET_ALL}")
    print(f"1. é‹è¡Œæ¼”ç¤º (æ¨è–¦)")
    print(f"2. æŸ¥çœ‹APIç”³è«‹æŒ‡å—")
    print(f"3. å…©è€…éƒ½è¦")
    
    choice = input(f"\nè«‹è¼¸å…¥é¸æ“‡ (1/2/3): ").strip()
    
    if choice in ['1', '3']:
        asyncio.run(run_demo())
    
    if choice in ['2', '3']:
        print_api_guide()
    
    print(f"\n{Fore.GREEN}æ„Ÿè¬ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼ï¼{Style.RESET_ALL}")
    print(f"{Fore.YELLOW}æº–å‚™å¥½APIå¯†é‘°å¾Œï¼Œå¯ä»¥é‹è¡Œ: python test_aisuite.py{Style.RESET_ALL}") 